{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af3f8833-c459-44cf-8a5b-0d848c1b7254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import Mapping, Optional, Sequence\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Source\n",
    "INCOMING_ROOT = \"s3a://landing-isis/opralog/incoming\"\n",
    "OPRALOGDB_TABLES: Mapping[str, Optional[Mapping[str, str]]] = dict(\n",
    "    LOGBOOKS=dict(unique_keys=(\"LOGBOOK_ID\",), partition_by=None),\n",
    "    LOGBOOK_ENTRIES=dict(\n",
    "        unique_keys=(\"LOGBOOK_ID\", \"ENTRY_ID\"), partition_by=None\n",
    "    ),\n",
    "    ENTRIES=dict(unique_keys=[\"ENTRY_ID\"], partition_by=None),\n",
    "    MORE_ENTRY_COLUMNS=dict(\n",
    "        unique_keys=[\"ENTRY_ID\", \"COLUMN_NO\", \"ENTRY_TYPE_ID\"],\n",
    "        partition_by=None,\n",
    "    ),\n",
    "    ADDITIONAL_COLUMNS=dict(\n",
    "        unique_keys=[\"COLUMN_NO\", \"ENTRY_TYPE_ID\"], partition_by=None\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Destination\n",
    "TARGET_CATALOG = \"isis\"\n",
    "TARGET_DB = \"cleaned\"\n",
    "OPRALOG_LOGBOOK_ENTRY = \"opralog_logbook_entry\"\n",
    "OPRALOG_LOGBOOK_ENTRY_COMMENT = \"opralog_logbook_entry_comment\"\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f48e6b87-f640-468f-b071-1094014484ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host-192-168-42-43.openstacklocal:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://data-accelerator.isis.cclrc.ac.uk:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x71f2d6bdf8f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .master(\"spark://data-accelerator.isis.cclrc.ac.uk:7077\")\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", os.environ[\"S3_ACCESS_KEY\"])\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", os.environ[\"S3_ACCESS_SECRET\"])\n",
    "        .getOrCreate()\n",
    ")\n",
    "spark.active()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47334a95-b757-4edb-91b9-e6935e828dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {TARGET_CATALOG}.{TARGET_DB}\")\n",
    "spark.sql(f\"USE {TARGET_CATALOG}.{TARGET_DB}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ef65075-c661-4bd5-ab60-1a0b7aedc32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting path 's3a://landing-isis/opralog/incoming/LOGBOOKS/full/2024/11/21/*.parquet'\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      47|\n",
      "+--------+\n",
      "\n",
      "Ingesting path 's3a://landing-isis/opralog/incoming/LOGBOOK_ENTRIES/full/2024/11/21/*.parquet'\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   48998|\n",
      "+--------+\n",
      "\n",
      "Ingesting path 's3a://landing-isis/opralog/incoming/ENTRIES/full/2024/11/21/*.parquet'\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   41663|\n",
      "+--------+\n",
      "\n",
      "Ingesting path 's3a://landing-isis/opralog/incoming/MORE_ENTRY_COLUMNS/full/2024/11/21/*.parquet'\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  511095|\n",
      "+--------+\n",
      "\n",
      "Ingesting path 's3a://landing-isis/opralog/incoming/ADDITIONAL_COLUMNS/full/2024/11/21/*.parquet'\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    1716|\n",
      "+--------+\n",
      "\n",
      "CPU times: user 8.57 ms, sys: 7.73 ms, total: 16.3 ms\n",
      "Wall time: 3.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load in temporary tables\n",
    "loadtype = \"full\"\n",
    "ingest_date = \"2024/11/21\"\n",
    "for tablename in OPRALOGDB_TABLES.keys():\n",
    "    sources = f\"{INCOMING_ROOT}/{tablename}/{loadtype}/{ingest_date}/*.parquet\"\n",
    "    print(f\"Ingesting path '{sources}'\")\n",
    "    df = spark.read.parquet(sources)\n",
    "    df.createOrReplaceTempView(tablename)\n",
    "    print(spark.sql(f\"SELECT COUNT(*) FROM {tablename}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "555f4502-7bba-497b-afbd-f1276c6a050a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 92 μs, sys: 2.1 ms, total: 2.19 ms\n",
      "Wall time: 19.9 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "table_ensure_exists = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {OPRALOG_LOGBOOK_ENTRY} (\n",
    "  entry_id LONG,\n",
    "  logbook_id LONG,\n",
    "  extra_column_no LONG,\n",
    "  extra_column_id LONG,\n",
    "  logbook_name STRING,\n",
    "  time_logged TIMESTAMP,\n",
    "  description STRING,\n",
    "  column_title STRING,\n",
    "  string_data STRING,\n",
    "  number_data DOUBLE\n",
    ")\n",
    "USING iceberg\n",
    "PARTITIONED BY (logbook_name, month(time_logged))\n",
    "\"\"\"\n",
    "spark.sql(table_ensure_exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b5f052f-5f24-40ea-a192-4421bde077ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 402 μs, sys: 2.36 ms, total: 2.76 ms\n",
      "Wall time: 42.4 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "snapshot_name = \"snapshot_without_comments\"\n",
    "snapshot_ddl = f\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW {snapshot_name} AS (\n",
    "    SELECT\n",
    "      CAST(ENTRIES.ENTRY_ID AS LONG) AS entry_id,\n",
    "      CAST(LOGBOOKS.LOGBOOK_ID AS LONG) AS logbook_id,\n",
    "      CAST(ADDITIONAL_COLUMNS.COLUMN_NO AS LONG) AS extra_column_no,\n",
    "      CAST(ADDITIONAL_COLUMNS.ENTRY_TYPE_ID AS LONG) AS extra_column_id,\n",
    "      CAST(TRIM(LOGBOOK_NAME) AS STRING) AS logbook_name,\n",
    "      TIME_LOGGED AS time_logged,\n",
    "      CAST(TRIM(ENTRY_DESCRIPTION) AS STRING) AS description,\n",
    "      CAST(TRIM(COL_TITLE) AS STRING) AS column_title,\n",
    "      CAST(TRIM(COL_DATA) AS STRING) AS string_data,\n",
    "      CAST(NUMBER_VALUE AS DOUBLE) AS number_data \n",
    "    FROM ENTRIES\n",
    "    JOIN LOGBOOK_ENTRIES ON LOGBOOK_ENTRIES.ENTRY_ID = ENTRIES.ENTRY_ID\n",
    "    JOIN LOGBOOKS ON LOGBOOKS.LOGBOOK_ID = LOGBOOK_ENTRIES.LOGBOOK_ID\n",
    "    LEFT OUTER JOIN MORE_ENTRY_COLUMNS ON MORE_ENTRY_COLUMNS.ENTRY_ID = ENTRIES.ENTRY_ID\n",
    "    LEFT OUTER JOIN ADDITIONAL_COLUMNS ON ADDITIONAL_COLUMNS.COLUMN_NO = MORE_ENTRY_COLUMNS.COLUMN_NO AND ADDITIONAL_COLUMNS.ENTRY_TYPE_ID = MORE_ENTRY_COLUMNS.ENTRY_TYPE_ID\n",
    "    WHERE\n",
    "      LOGBOOK_ENTRIES.LOGBOOK_ID = PRINCIPAL_LOGBOOK\n",
    "      AND (COL_DATA IS NOT NULL OR NUMBER_VALUE IS NOT NULL)\n",
    ")\n",
    "\"\"\"\n",
    "spark.sql(snapshot_ddl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc51a739-98fa-48d5-8ae1-e1f7d9eb3566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.48 ms, sys: 1.6 ms, total: 9.08 ms\n",
      "Wall time: 21.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "merge_ddl = f\"\"\"\n",
    "MERGE INTO {OPRALOG_LOGBOOK_ENTRY} t\n",
    "USING {snapshot_name} s\n",
    "ON t.logbook_id = s.logbook_id AND t.entry_id = s.entry_id AND t.extra_column_no = s.extra_column_no AND t.extra_column_id = s.extra_column_id\n",
    "WHEN NOT MATCHED THEN INSERT *\n",
    "\"\"\"\n",
    "spark.sql(merge_ddl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f2e41b3-dd66-4f78-abe6-8565533675b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"DROP VIEW {snapshot_name}\")\n",
    "del snapshot_ddl\n",
    "del snapshot_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b239aab1-a941-4e15-9555-f3cb48e51436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 811 μs, total: 811 μs\n",
      "Wall time: 12.2 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "snapshot_name = \"snapshot_comments\"\n",
    "snapshot_ddl = f\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW {snapshot_name} AS (\n",
    "    SELECT\n",
    "      CAST(ENTRIES.ENTRY_ID AS LONG) AS entry_id,\n",
    "      CAST(TRIM(SHADOW_COMMENT) AS STRING) AS comment_text\n",
    "    FROM ENTRIES\n",
    ")\n",
    "\"\"\"\n",
    "spark.sql(snapshot_ddl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73782f16-ad10-475c-b1ab-1dbe7dde5684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.69 ms, sys: 98 μs, total: 1.79 ms\n",
      "Wall time: 12.8 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "table_ensure_exists = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {OPRALOG_LOGBOOK_ENTRY_COMMENT} (\n",
    "  entry_id LONG,\n",
    "  comment_text STRING\n",
    ")\n",
    "USING iceberg\n",
    "\"\"\"\n",
    "spark.sql(table_ensure_exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ae91ace-36f9-4e17-b378-be7e489996a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.38 ms, sys: 1.18 ms, total: 2.56 ms\n",
      "Wall time: 2.37 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "merge_snapshot = f\"\"\"\n",
    "MERGE INTO {OPRALOG_LOGBOOK_ENTRY_COMMENT} t\n",
    "USING {snapshot_name} s\n",
    "ON t.entry_id = s.entry_id\n",
    "WHEN NOT MATCHED THEN INSERT *\n",
    "\"\"\"\n",
    "spark.sql(merge_snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "875eeba2-3e7c-4f6b-a126-4643dd15489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"DROP VIEW {snapshot_name}\")\n",
    "del merge_snapshot\n",
    "del snapshot_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

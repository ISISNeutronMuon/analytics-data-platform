---
- name: Ensure working directory for Docker image build exists
  become: yes
  ansible.builtin.file:
    path: "{{ spark_image_build_path }}"
    state: directory
    mode: "u=rwx,g=rx,o=rx"

- name: Ensure Docker image build files are synchronized
  become: yes
  ansible.posix.synchronize:
    src: ./
    dest: "{{ spark_image_build_path }}/"
    recursive: yes
    delete: yes

- name: Ensure templated Docker image build files are present
  become: yes
  ansible.builtin.template:
    src: "{{ item }}"
    dest: "{{ spark_image_build_path }}/{{ item | trim('.j2') }}"
  loop:
    - Dockerfile.j2
    - spark-defaults.conf.j2

- name: Build container image
  become: yes
  community.docker.docker_image_build:
    name: spark-iceberg
    path: "{{ spark_image_build_path }}"
    rebuild: always

- name: Run container
  become: yes
  community.docker.docker_container:
    name: spark
    image: spark-iceberg
    state: started
    cleanup: true
    detach: true
    restart_policy: unless-stopped
    env:
      AWS_REGION: "{{ s3_region }}"
      AWS_ACCESS_KEY_ID: "{{ s3_access_key_id }}"
      AWS_SECRET_ACCESS_KEY: "{{ s3_access_secret }}"
    published_ports:
      - "{{ spark_controller_ui_port }}:8080"
      - "{{ spark_connect_port }}:15002"
    volumes:
      - "{{ cephfs_mount_path }}/staging/:/staging:ro"

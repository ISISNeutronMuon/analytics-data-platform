---
# WARNING: This needs to match the version running in the Spark Dockerfile
- name: Install required APT packages
  become: true
  ansible.builtin.apt:
    pkg:
      - openjdk-17-jdk
      - python3
      - python3-dev
    state: present

- name: Ensure persistent home directory root exists
  become: true
  ansible.builtin.file:
    path: "{{ jupyterhub_home_root_path }}"
    state: directory
    mode: "0755"

- name: Change default directory for home directories
  become: true
  ansible.builtin.lineinfile:
    path: /etc/default/useradd
    regexp: "^HOME="
    line: "HOME={{ jupyterhub_home_root_path }}"

- name: Ensure skeleton ipython directory exists
  become: true
  ansible.builtin.file:
    path: "/etc/skel/.ipython"
    state: directory
    mode: "0755"

- name: Add additional skeleton content for each new user created
  become: true
  ansible.posix.synchronize:
    use_ssh_args: true
    src: ipython/
    dest: /etc/skel/.ipython/
    archive: false
    recursive: true
    delete: true

- name: Download The Littlest JupyterHub bootstrap script
  ansible.builtin.get_url:
    url: https://github.com/jupyterhub/the-littlest-jupyterhub/raw/refs/tags/2.0.0/bootstrap/bootstrap.py
    dest: /tmp/bootstrap.py
    mode: "u=rwx,g=rx,o=rx"

# Start the default server once to create the directory structure
# We'll then copy our configuration over and reload
- name: Run bootstrap script
  become: true
  ansible.builtin.command:
    cmd: python3 /tmp/bootstrap.py
    creates: /opt/tljh/installer.log

- name: Ensure common set of pip packages are present in tljh user environment
  become: true
  ansible.builtin.pip:
    executable: /opt/tljh/user/bin/pip
    name:
      - fsspec==2024.9.0
      - influxdb==5.3.2
      - lxml == 5.3.0
      - matplotlib==3.9.1
      - pandas==2.2.2
      - prettytable==3.10.2
      - pyarrow==17.0.0
      - pyspark==3.5.2
      - s3fs==2024.9.0
      - tabulate==0.9.0

- name: Query location of PySpark root (SPARK_HOME)
  become: true
  ansible.builtin.command:
    cmd: /opt/tljh/user/bin/python -c "import pyspark;print(pyspark.__path__[0])"
  register: pyspark_root

- name: Ensure PySpark root conf path exists
  become: true
  ansible.builtin.file:
    path: "{{ pyspark_root.stdout }}/conf"
    state: directory
    mode: "0755"

- name: Ensure Spark config files are present
  become: true
  ansible.builtin.template:
    src: spark/spark-defaults.conf.j2
    dest: "{{ pyspark_root.stdout }}/conf/spark-defaults.conf"
    mode: "u=rw,g=r,o=r"

- name: Ensure JupyterHub config files are present and up to date
  become: true
  ansible.builtin.template:
    src: "{{ jupyterhub_template }}"
    dest: "/opt/tljh/{{ jupyterhub_template | replace('.j2', '') }}"
    mode: "u=rw,g=r,o=r"
  loop:
    - config/config.yaml.j2
    - config/jupyterhub_config.d/00-spawner.py.j2
    - config/jupyterhub_config.d/01-jupyterhub.py.j2
  loop_control:
    loop_var: jupyterhub_template
  register: jupyterhub_configs

- name: Ensure Jupyter config files are present
  become: true
  ansible.posix.synchronize:
    use_ssh_args: true
    src: jupyter/
    dest: /opt/tljh/notebook/
    archive: false
    recursive: true
    delete: true

- name: Reload JupyterHub
  become: true
  ansible.builtin.command:
    cmd: tljh-config reload hub
  when: jupyterhub_configs.changed

[runtime]
log_level = "WARNING" # the system log level of dlt
# use the dlthub_telemetry setting to enable/disable anonymous usage data reporting, see https://dlthub.com/docs/reference/telemetry
dlthub_telemetry = false

[sources.sql_database.credentials]
drivername = "mssql+pymssql"

[sources.sql_database]
schema = "dbo"

[[sources.sql_database.tables]]
name = "Entries"
# Spark seems to have an issue with seeing a table named 'entries' regardless of the namespace it is in
# so we rename it
destination_name = "user_entries"
incremental_id = "EntryId"
html_to_markdown_columns = ["AdditionalComment"]

[[sources.sql_database.tables]]
name = "ChapterEntry"
incremental_id = "LogbookEntryId"

[[sources.sql_database.tables]]
name = "LogbookChapter"
incremental_id = "LogbookChapterNo"

[[sources.sql_database.tables]]
name = "Logbooks"
incremental_id = "LogbookId"

[[sources.sql_database.tables]]
name = "MoreEntryColumns"
incremental_id = "MoreEntryColumnId"

[[sources.sql_database.tables]]
name = "AdditionalColumns"
incremental_id = "AdditionalColumnId"

[sources.data_writer]
file_max_items = 100000

[normalize]
workers = 3

[load]
delete_completed_jobs = true
raise_on_max_retries = 1
workers = 1
